## Introduction to Ethical Principles in AI Design

The text discusses the importance of embedding ethical principles and values in the design and deployment of artificial intelligence (AI) systems. It highlights the efforts of organizations like the EU High-Level Expert Group on AI and the IEEE, which have formulated ethical principles that AI applications should adhere to, including respect for human autonomy, prevention of harm, fairness, and explicability.

## Challenges in Embedding Values in AI Systems

The author, Ibo van de Poel, raises a critical question about how we can ensure and verify that AI systems respect and embody these ethical values. The discussion extends into the philosophical realm, where different perspectives on whether technologies can be value-laden are explored. The text references various philosophical accounts and critiques regarding the embodiment of values in technology.

## Proposed Framework for Value Embodiment

Van de Poel proposes a framework for determining when an AI system embodies certain values. This framework is based on the concept that values can be intentionally embedded in AI systems through design activities. The framework emphasizes that AI systems should be viewed not just as isolated technical artifacts but as sociotechnical systems, which include human agents, institutions, and now, artificial agents and technical norms.

## Sociotechnical Systems and AI

The text elaborates on the nature of sociotechnical systems, which traditionally consist of technological artifacts, human agents, and institutional rules. AI systems are described as hybrid systems that also include artificial agents (AAs) and technical norms. AAs, unlike traditional technical artifacts, are autonomous, interactive, and adaptive, which presents both opportunities and challenges for value embedding.

## Specific Characteristics of AI Systems

AI systems' ability to autonomously interact with their environment and adapt based on these interactions creates new opportunities for embedding values. However, this adaptivity also poses risks, as it might lead to the unintended disembodiment of originally embedded values. The text discusses the roles of artificial agents and technical norms in regulating interactions within AI systems, highlighting the differences from traditional sociotechnical systems.

## Conclusion and Lessons for AI Design

In conclusion, the article aims to extend the value-embedding account to AI systems by offering a conceptualization of values and the process of embedding them in technology. It also provides a detailed discussion on the components of AI systems and how each can embody values. The author suggests tentative lessons for better embedding values in AI systems, emphasizing the need for a robust framework that accommodates the unique characteristics of AI as part of broader sociotechnical systems.

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/15856614/321f383b-40bb-43ab-9f24-e2be37b17d34/paste.txt

The pasted text delves into the complex concept of "value" as it pertains to the realm of artificial intelligence (AI) systems, offering a nuanced exploration of how values are defined, embodied, and realized within these systems. The discussion is structured around several key themes, which are outlined below.

## Defining Values

The text begins by addressing the challenge of defining "value," a term widely used across various disciplines including philosophy, economics, sociology, psychology, and anthropology. It highlights that values are normative, expressing what is considered "good" or "desirable," and are used to evaluate states of affairs or entities in terms of goodness and badness. This section also distinguishes between evaluative and deontic aspects of normativity, with values falling into the former category.

## The Nature of Valuing

A critical examination of the act of valuing is presented, noting the distinction between valuing something and that thing being inherently valuable. The text argues that a correspondence should exist between normative reasons for valuing something and it being of value. This perspective helps to navigate the complexities of valuing, especially in cases where individuals may value things that are not inherently valuable or fail to value things that are.

## Embodied Values in AI Systems

The concept of "embodied values" is introduced as a means to assess whether AI systems comply with articulated ethical values. The text outlines two interpretations of compliance: one based on the designers' intentions and another on the values realized in the operation of an AI system. It critiques both approaches for being susceptible to the "wrong kind of reasons problem," advocating instead for a focus on values that are intentionally and successfully embedded in an AI system by its designers.

## Intended, Embodied, and Realized Values

A detailed discussion on the relationship between intended, embodied, and realized values in AI systems is provided. Intended values are those the system's designers aim to integrate, while embodied values are those that are both intended and realized when the system is used properly. Realized values, however, may differ from embodied values due to unforeseen uses or outcomes. The text emphasizes the dynamic nature of design, highlighting the importance of feedback loops and redesign in aligning intended, embodied, and realized values.

## AI Systems as Sociotechnical Systems

Finally, the text positions AI systems within the broader context of sociotechnical systems, emphasizing the role of intentional agents, physical-causal artifacts, rules, technical artifacts, human agents, and institutions in the design and operation of AI systems. It underscores the ongoing nature of design, particularly in AI systems, which may develop unforeseen properties due to their adaptive abilities.

In summary, the pasted text offers a comprehensive exploration of how values are conceptualized, evaluated, and integrated within AI systems. It underscores the importance of aligning ethical values with the design and operation of AI systems, advocating for a nuanced approach that considers the dynamic and complex nature of these sociotechnical systems.

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/15856614/a9b63c09-9986-4d9c-906f-8d28188e056d/paste.txt

## Overview of AI Systems as Sociotechnical Systems

The text discusses the concept of sociotechnical systems, particularly focusing on AI systems. It defines sociotechnical systems as those that rely not only on technical hardware but also on human behavior and social institutions for their functioning. AI systems are distinguished by including artificial agents and technical norms, which are understood in causal or physical terms rather than intentional terms.

### Building Blocks of Sociotechnical Systems

1. **Technical Artifacts**: These are physical objects designed to fulfill a specific function, which requires understanding both the laws of nature and human intentions. Technical artifacts combine physical structures with use plans, which describe how the artifact should be used to achieve its intended function.

2. **Agents**: Agents can be human or artificial. Artificial agents (AAs) possess properties like autonomy, interactivity, and adaptivity, which are typically associated with human agents. However, AAs lack human characteristics such as consciousness, free will, and moral agency.

3. **Institutions and Technical Norms**: For human agents, rules are conceptualized as institutions based on social norms that dictate behavior and are often upheld by sanctions. In contrast, artificial agents follow technical norms, which are understood in causal-physical terms and do not involve intentions.

## Embedding Values in AI Systems

The text explores how individual components of sociotechnical systems can embody values. It argues that a technological artifact embodies a value if it is designed with the intention to achieve that value and its use contributes to realizing that value. Several examples illustrate this concept:

- **Sea Dikes**: Designed for safety against flooding and effectively protect against it, thus embodying the value of safety.
- **Bread Knife**: Designed to cut bread, not to kill, hence does not embody the disvalue of killing despite its potential misuse.
- **Pacemaker**: Intended to enhance well-being, but a poorly designed one fails to do so and thus does not embody its intended value.

The text also addresses the challenge of unintended consequences, suggesting that unintended but systematically occurring outcomes do not necessarily embody disvalues unless they are recognized and redesigned to avoid such outcomes. This leads to a discussion on the obligation of designers and users to redesign artifacts to embody intended positive values and avoid disvalues.

## Conclusion on Sociotechnical Systems and AI

The text concludes that sociotechnical systems, especially those involving AI, are complex and require careful consideration of how values are integrated into their design and use. It emphasizes the importance of intentionality in design to ensure that technological artifacts embody desirable values and do not inadvertently lead to negative outcomes.

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/15856614/5537ada7-c4cd-44fb-9644-6db9557c762c/paste.txt

## Overview of Institutions and the ADICO Grammar

The text discusses the concept of institutions, which are understood as rules that can be either formal (like legal rules or operational instructions) or informal. The ADICO grammar, developed by Crawford and Ostrom, is introduced as a tool for analyzing institutional rules. This grammar categorizes institutions based on five elements: Attributes (A), Deontic operator (D), Aim (I), Conditions (C), and Or else (O). These elements help in distinguishing between shared strategies, norms, and rules, each defined by specific combinations of these elements.

- **Shared Strategies (AIC)**: These are strategies without a deontic operator or sanctions, followed for reasons of self-interest, like using an umbrella when it rains.
- **Norms (ADIC)**: These include a deontic operator but lack sanctions, driven by normative expectations, like greeting neighbors.
- **Rules (ADICO)**: These contain all elements, including sanctions for non-compliance, like traffic rules that include fines.

## Embedding Values in Institutions

The text extends the discussion to how values are embedded in institutions, drawing parallels to the embedding of values in technological artifacts. An institution embodies a value if it is designed to achieve that value and is conducive to the value when followed under appropriate conditions. Examples include:
- Traffic rules designed for safety.
- Neighborhood norms promoting politeness.
- Shared strategies facilitating convenience.

The institution must meet both design and conduciveness criteria to embody a value. If these conditions are not met, the institution does not embody the value, though it may still influence behaviors or be redesigned to align with desired values.

## Role of Human Agents in Sociotechnical Systems

The text also explores the role of human agents within sociotechnical systems, emphasizing their dual roles as users and designers. Human agents are described as part of these systems, where they interact with technical artifacts and institutions that embody specific values. Their behavior is influenced by the values embedded in the system and their personal values. Human agents are capable of reflecting on their roles and the system's outcomes, potentially leading to changes in the system based on their moral values.

- **Intentional-Causal Relation**: Human actions within these systems are both intentional (based on values and intentions) and causal (involving physical activities).
- **Outcome Evaluation**: Agents evaluate the outcomes based on the system's values and their personal values, which may lead to behavioral changes or system redesigns.

In summary, the text provides a detailed analysis of how institutions function as systems of rules with embedded values and how human agents interact with these systems, potentially influencing and modifying them based on their values and reflections.

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/15856614/7d10c814-61c6-4191-8310-3b78757c11bd/paste.txt

The pasted text delves into the intricate relationship between artificial agents (AAs), values, and the embedding of these values within artificial intelligence (AI) systems. It also explores the regulation of behavior in artificial multi-agent systems through technical norms. The text is structured around several key concepts and distinctions, which are summarized below in detail.

## Artificial Agents and Value Embedding

### Definition and Roles of Artificial Agents
Artificial Agents (AAs) are defined as computer and robot systems characterized by autonomy, interactivity, and adaptability. These agents have the potential to take over roles traditionally played by human agents within sociotechnical systems, such as operating within these systems autonomously while respecting certain values and adapting to achieve measurable outcomes.

### Differences Between Human and Artificial Agents
A significant distinction is made between human and artificial agents. Unlike humans, AAs are designed entities, which allows them to embody values directly. However, they lack the ability to embed values in other entities due to the absence of intentionality. This distinction positions AAs closer to technical artifacts, albeit with notable differences due to their autonomous, interactive, and adaptive capabilities.

### Value Embodiment and Disembodiment
The text discusses how AAs can embody values initially but also warns of the potential for these agents to "disembody" values through adaptation. This disembodiment occurs when an AA's adaptations lead it away from promoting the value it was initially designed to embody.

## Ethical Agents and Their Types
James Moorâ€™s taxonomy of ethical agents is introduced to categorize AAs based on their ethical capabilities:
- **Ethical Impact Agents**: Affect their environment ethically without embodying specific values.
- **Implicit Ethical Agents**: Programmed to behave according to certain values.
- **Explicit Ethical Agents**: Capable of representing and reasoning about ethical categories.
- **Full Ethical Agents**: Possess human-like qualities such as consciousness and moral agency, which are currently beyond the reach of AI.

The text emphasizes the challenges in designing AAs as full ethical agents and discusses the potential and limitations of implicit and explicit ethical agents in embodying and maintaining values.

## Norms in Artificial Multi-agent Systems

### Regulation Through Code
The behavior of AAs, unlike human agents, is directly regulated by code or technical norms. This section explores how social institutions can indirectly influence AAs through the translation of social norms into computer code, facilitating the regulation of AA behavior and interactions.

### Technical Norms and Their Creation
Technical norms can be established through offline design by system designers or autonomously by AAs through interaction with their environment or other agents. These norms are crucial for guiding the behavior of AAs in multi-agent systems.

### Value Embedding in Technical Norms
The text concludes with a discussion on how technical norms can embody values. A technical norm embodies a value if it is designed for that value and its execution within the system promotes that value. This concept extends the idea of value embedding from individual AAs to the broader framework of multi-agent systems.

In summary, the pasted text provides a comprehensive overview of the role of artificial agents in sociotechnical systems, the challenges of embedding values in AAs, the categorization of ethical agents, and the regulation of AA behavior through technical norms. It highlights the complexities involved in designing AAs that can both embody and maintain ethical values, as well as the potential for using technical norms to regulate behavior in artificial multi-agent systems.

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/15856614/ff1ed403-8af6-49e0-9d04-ef03e8be0729/paste.txt

## Introduction to Value Embedding in AI Systems

The text discusses the concept of embedding values in artificial intelligence (AI) systems, focusing on the systemic level rather than just the component level. It introduces a hypothetical scenario where an AI system is designed entirely with a specific value in mind. The core proposition is that a value $$V$$ is considered embodied in a sociotechnical system $$S$$ if the system is conducive to $$V$$ because it has been designed for $$V$$. This involves two main conditions: the system being designed for the value, and the realization of the value when all relevant institutions and technical norms are followed.

## Conditions for Value Embodiment

The text elaborates on the conditions for a value to be embodied in a system. It clarifies that not all components of the system need to embody the value directly, as long as the system, through adherence to relevant institutions and norms, is conducive to the value. This perspective acknowledges that many AI systems are not designed in their entirety but evolve over time. Therefore, it suggests a more flexible approach to value embodiment, focusing on components designed with the value in mind, rather than the entire system.

## Sociotechnical Systems and AI

The distinction between sociotechnical systems and their components is highlighted, noting that while components might be fully designed with a value in mind, systems often evolve and are not entirely designed from the outset. This evolution poses challenges for embedding values, as it requires continuous adaptation and redesign to ensure that the system remains conducive to the intended values.

## Embedding Values through Redesign and Institutions

The text suggests that embedding values in AI systems can be achieved by redesigning certain components, particularly institutions, which play a crucial role in regulating interactions within the system. It argues that focusing on technical norms and institutions might be more effective than focusing solely on artificial agents (AAs), as these norms regulate the behavior of AAs and ensure the system's alignment with desired values.

## Lessons for Embedding Values in AI Systems

### Unique Characteristics of AI Systems

AI systems are distinguished by their autonomy, adaptability, and interactivity, which allow them to evolve and acquire new features during operation. This evolution offers unique opportunities and challenges for value embedding, necessitating continuous monitoring and redesign to ensure that the system embodies desired societal values.

### Human Oversight and Continuous Redesign

The text emphasizes the need for human oversight and continuous redesign to manage the unintended consequences of AI systems and ensure they embody the right values. It suggests that while AI systems' autonomy and adaptability reduce the need for human intervention, meaningful human control remains essential for embedding and maintaining values in these systems.

### System and Component Level Considerations

Finally, the text advises that embedding values in AI systems requires attention at both the system and component levels. It critiques the sole focus on designing ethical AAs and advocates for considering technical norms and other system components. This approach aims to mitigate risks and ensure that values remain embodied in the system as it evolves.

In summary, the text provides a comprehensive framework for understanding and implementing value embedding in AI systems, emphasizing the importance of design, institutions, continuous adaptation, and human oversight.

Citations:
[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/15856614/c09a1a7c-570e-4982-b588-8969c24e0aaf/paste.txt
